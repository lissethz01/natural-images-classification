{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "natural_images_cnn_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Natural Images Classification using CNN\n",
        "## CECS 456 - Deep Learning Project\n",
        "\n",
        "**Dataset:** Natural Images (8 Classes)\n",
        "- airplane, car, cat, dog, flower, fruit, person, motorbike\n",
        "\n",
        "**Objective:** Build and train a CNN to classify natural images into 8 categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload"
      },
      "source": [
        "## 2. Upload Dataset\n",
        "\n",
        "**Instructions:**\n",
        "1. Download the Natural Images dataset from: https://www.kaggle.com/datasets/prasunroy/natural-images\n",
        "2. Upload the zip file using the cell below\n",
        "3. Wait for extraction to complete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upload_data"
      },
      "source": [
        "# Upload dataset zip file\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"Please upload your natural-images.zip file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the zip file\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"Extracting {filename}...\")\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/')\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "# Set the path to dataset (adjust if needed)\n",
        "data_dir = '/content/natural_images'\n",
        "\n",
        "# Verify the structure\n",
        "if os.path.exists(data_dir):\n",
        "    print(f\"\\nDataset found at: {data_dir}\")\n",
        "    print(f\"Classes: {os.listdir(data_dir)}\")\n",
        "else:\n",
        "    print(\"ERROR: Dataset not found. Please check the path.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "explore"
      },
      "source": [
        "## 3. Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "explore_data"
      },
      "source": [
        "# Count images in each class\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "print(f\"Number of classes: {len(classes)}\")\n",
        "print(f\"Class names: {classes}\\n\")\n",
        "\n",
        "total_images = 0\n",
        "print(\"Images per class:\")\n",
        "print(\"-\" * 30)\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        num_images = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        total_images += num_images\n",
        "        print(f\"{class_name:15s}: {num_images:4d} images\")\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"Total images: {total_images}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize"
      },
      "source": [
        "## 4. Visualize Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "visualize_samples"
      },
      "source": [
        "# Display sample images from each class\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    \n",
        "    if image_files:\n",
        "        # Load first image from this class\n",
        "        img_path = os.path.join(class_path, image_files[0])\n",
        "        img = plt.imread(img_path)\n",
        "        \n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{class_name}\\n({len(image_files)} images)\", fontsize=12)\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Sample images saved as 'sample_images.png'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prepare"
      },
      "source": [
        "## 5. Prepare Data with Augmentation\n",
        "\n",
        "Data augmentation helps prevent overfitting by creating variations of training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prepare_data"
      },
      "source": [
        "# Set parameters\n",
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,              # Normalize pixel values to [0,1]\n",
        "    validation_split=0.2,        # Use 20% for validation\n",
        "    rotation_range=20,           # Rotate images randomly up to 20 degrees\n",
        "    width_shift_range=0.2,       # Shift horizontally by 20%\n",
        "    height_shift_range=0.2,      # Shift vertically by 20%\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    zoom_range=0.2,              # Zoom in/out by 20%\n",
        "    fill_mode='nearest'          # Fill in missing pixels after transformations\n",
        ")\n",
        "\n",
        "# Training set (with augmentation)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Validation set (no augmentation, only rescaling)\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {val_generator.samples}\")\n",
        "print(f\"Number of classes: {train_generator.num_classes}\")\n",
        "print(f\"Class indices: {train_generator.class_indices}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model"
      },
      "source": [
        "## 6. Build CNN Model\n",
        "\n",
        "Architecture:\n",
        "- 4 Convolutional blocks (Conv2D + MaxPooling)\n",
        "- Progressively increasing filters: 32 → 64 → 128 → 128\n",
        "- Dropout for regularization\n",
        "- Dense layers for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "build_model"
      },
      "source": [
        "# Build the CNN model\n",
        "model = keras.Sequential([\n",
        "    # Input layer\n",
        "    keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    \n",
        "    # First convolutional block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Second convolutional block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Third convolutional block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Fourth convolutional block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Flatten and dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),                              # Prevent overfitting\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer\n",
        "], name='Natural_Images_CNN')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "# Count total parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal trainable parameters: {total_params:,}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train"
      },
      "source": [
        "## 7. Train the Model\n",
        "\n",
        "This will take approximately 15-20 minutes on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "train_model"
      },
      "source": [
        "# Set training parameters\n",
        "EPOCHS = 25\n",
        "\n",
        "print(f\"Starting training for {EPOCHS} epochs...\\n\")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('natural_images_cnn_model.h5')\n",
        "print(\"Model saved as 'natural_images_cnn_model.h5'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results"
      },
      "source": [
        "## 8. Visualize Training Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plot_results"
      },
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot loss\n",
        "axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Loss', fontsize=12)\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Training plots saved as 'training_results.png'\")\n",
        "\n",
        "# Print final metrics\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"FINAL RESULTS\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Training Accuracy:   {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "print(f\"Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "print(f\"Training Loss:       {final_train_loss:.4f}\")\n",
        "print(f\"Validation Loss:     {final_val_loss:.4f}\")\n",
        "print(f\"{'='*50}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluate"
      },
      "source": [
        "## 9. Detailed Evaluation & Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evaluate_model"
      },
      "source": [
        "# Get predictions on validation set\n",
        "print(\"Generating predictions on validation set...\")\n",
        "val_generator.reset()\n",
        "predictions = model.predict(val_generator, steps=len(val_generator), verbose=1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = val_generator.classes\n",
        "class_labels = list(val_generator.class_indices.keys())\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))\n",
        "\n",
        "# Calculate overall accuracy\n",
        "correct_predictions = np.sum(predicted_classes == true_classes)\n",
        "total_predictions = len(true_classes)\n",
        "overall_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "print(f\"\\nOverall Validation Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n",
        "print(f\"Correct Predictions: {correct_predictions}/{total_predictions}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "confusion_matrix"
      },
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_labels, yticklabels=class_labels,\n",
        "            cbar_kws={'label': 'Number of Predictions'})\n",
        "plt.title('Confusion Matrix - Natural Images Classification', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion matrix saved as 'confusion_matrix.png'\")\n",
        "\n",
        "# Calculate per-class accuracy\n",
        "print(\"\\nPer-Class Accuracy:\")\n",
        "print(\"-\" * 40)\n",
        "for i, class_name in enumerate(class_labels):\n",
        "    class_correct = cm[i, i]\n",
        "    class_total = cm[i, :].sum()\n",
        "    class_acc = class_correct / class_total if class_total > 0 else 0\n",
        "    print(f\"{class_name:15s}: {class_acc:.4f} ({class_acc*100:.2f}%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "predict"
      },
      "source": [
        "## 10. Test Predictions on Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "test_predictions"
      },
      "source": [
        "# Get some sample predictions\n",
        "val_generator.reset()\n",
        "sample_batch = next(val_generator)\n",
        "sample_images = sample_batch[0][:9]  # First 9 images\n",
        "sample_labels = sample_batch[1][:9]\n",
        "\n",
        "# Make predictions\n",
        "sample_predictions = model.predict(sample_images)\n",
        "sample_pred_classes = np.argmax(sample_predictions, axis=1)\n",
        "sample_true_classes = np.argmax(sample_labels, axis=1)\n",
        "\n",
        "# Plot predictions\n",
        "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(9):\n",
        "    axes[i].imshow(sample_images[i])\n",
        "    \n",
        "    true_label = class_labels[sample_true_classes[i]]\n",
        "    pred_label = class_labels[sample_pred_classes[i]]\n",
        "    confidence = sample_predictions[i][sample_pred_classes[i]] * 100\n",
        "    \n",
        "    # Color code: green if correct, red if wrong\n",
        "    color = 'green' if sample_true_classes[i] == sample_pred_classes[i] else 'red'\n",
        "    \n",
        "    axes[i].set_title(\n",
        "        f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%\",\n",
        "        color=color, fontsize=10, fontweight='bold'\n",
        "    )\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Sample predictions saved as 'sample_predictions.png'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download"
      },
      "source": [
        "## 11. Download Results\n",
        "\n",
        "Download all generated files for your report and GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "download_files"
      },
      "source": [
        "# List of files to download\n",
        "files_to_download = [\n",
        "    'natural_images_cnn_model.h5',\n",
        "    'sample_images.png',\n",
        "    'training_results.png',\n",
        "    'confusion_matrix.png',\n",
        "    'sample_predictions.png'\n",
        "]\n",
        "\n",
        "print(\"Downloading files...\\n\")\n",
        "for filename in files_to_download:\n",
        "    if os.path.exists(filename):\n",
        "        files.download(filename)\n",
        "        print(f\"✓ Downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"✗ Not found: {filename}\")\n",
        "\n",
        "print(\"\\nAll files downloaded!\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Upload these files to your GitHub repository\")\n",
        "print(\"2. Use the results in your project report\")\n",
        "print(\"3. Make sure to cite the accuracy values shown above\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## 12. Project Summary\n",
        "\n",
        "**What We Did:**\n",
        "1. Loaded and explored the Natural Images dataset (8 classes)\n",
        "2. Applied data augmentation to prevent overfitting\n",
        "3. Built a CNN with 4 convolutional blocks\n",
        "4. Trained for 25 epochs with validation\n",
        "5. Evaluated performance with confusion matrix\n",
        "6. Analyzed per-class accuracy\n",
        "\n",
        "**Key Findings:**\n",
        "- Model achieved XX% validation accuracy\n",
        "- Best performing classes: [based on confusion matrix]\n",
        "- Most confused classes: [based on confusion matrix]\n",
        "- Data augmentation helped generalization\n",
        "\n",
        "**Files Generated:**\n",
        "- `natural_images_cnn_model.h5` - Trained model\n",
        "- `sample_images.png` - Dataset samples\n",
        "- `training_results.png` - Training curves\n",
        "- `confusion_matrix.png` - Classification performance\n",
        "- `sample_predictions.png` - Example predictions\n",
        "\n",
        "**Remember to:**\n",
        "- Update your report with the actual accuracy values\n",
        "- Analyze which classes were confused and why\n",
        "- Discuss potential improvements\n",
        "- Upload everything to GitHub\n",
        "\n",
        "---\n",
        "**Author:** [Your Name]\n",
        "\n",
        "**Course:** CECS 456 - Machine Learning\n",
        "\n",
        "**Date:** [Current Date]"
      ]
    }
  ]
}
